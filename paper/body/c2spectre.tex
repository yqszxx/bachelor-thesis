% !TeX root = ../thesis.tex

\chapter{针对处理器微架构的攻击}{Attacks on Processor Microarchitectures}
本章将基于中科院计算所的香山高性能开源RISC-V处理器，利用处理器中的乱序执行
机制和缓存侧信道，实现一种以读取同一地址空间中存储器上任意地址内的数据为目的
的攻击方案。这种攻击方案最早在2018年初被\citet{kocher_spectre_2019}发现，
命名为Spectre（幽灵）漏洞，并在Intel Skylake及Kaby Lake微架构上得到了验证。
本研究将在香山处理器的雁栖湖微架构上实现使用与Spectre相同原理的攻击实例。


\section{高性能处理器设计理念}{High-Performance Processor Design Philosophy} \label{sec:design-philo}
处理器设计中最主要的性能指标是单位时间内可以执行的指令数量。由于目前主流的数字
设计多采用同步设计方案（寄存器对同一个时钟边沿敏感），所以单位时间内可以执行的
指令数量就可以通过单位时间内的处理器时钟周期数量（也就是处理器的时钟频率）和每
个处理器时钟周期内可执行的指令数量（Instruction Per Cycle, IPC）相乘得到，所
以，处理器的性能与其主频和IPC都成正比，如公式\ref{eq:perf}所示。
\begin{equation}
    Performance \propto Frequency \times IPC \label{eq:perf}
\end{equation}

可见，要想提高处理器的性能，就要分别提高主频和IPC。

为了提升处理器的主频，工程师们进行了不懈的努力。处理器自上世纪70年代初进入集成
电路时代后，最初处理器的主频提升主要来自于集成电路制造工艺的优化：随着新工艺的
产生，半导体器件的漏电流及负载电容都有减小，器件间的线延迟也在减小，从而使处理
器主频不断提升：1974年，最早的个人电脑Altair 8800中使用的Intel 8080 CPU的主
频为2MHz；1992年，HP公司的PA-7100和DEC公司的Alpha 21064处理器主频突破了100MHz；
2000年，AMD公司的Athlon处理器主频达到1GHz；2002年，Intel公司的Pentium 4处理
器主频达到3GHz\cite{enwiki:clock}。

但半导体器件的动态功耗是由公式\ref{eq:pwr}决定的：
\begin{equation}
    P \propto f C V^2 \label{eq:pwr}
\end{equation}

其中$P$为功率，其主要表现形式为热能；$f$为工作频率，在处理器中即为主频；$C$为
电容，由制造工艺决定；$V$为工作电压。随着半导体制程不断下降，处理器的集成度在
升高，即单位面积内的半导体器件数量在上升，也意味着处理器的功率密度的提升。随着
越来越多的产生热量的器件集中在更小的面积内，如何控制处理器的温度以避免高温损坏
半导体器件就成了一项严峻的挑战。目前的散热技术只允许在处理器晶粒大小的面积上产
生数百瓦特的热功率，所以公式中$P$项无法有效提升。公式中的$C$项与半导体制程成
反比，但随着摩尔定律的放缓，半导体制造的特征尺寸无法快速缩减，导致电容也无法大
幅降低。而公式中的另一项$V$，受到半导体器件阈值电压的限制，目前已经降无可降。
由于上述种种限制，处理器的主频难以继续提升，这就是所谓的功耗墙。

回到公式\ref{eq:perf}中，在处理器的频率无法得到有效提高的情况下，要想提高处理
器的性能，就只能以提高处理器的IPC作为切入点。

早期的处理器设计中，每条指令都需要多个周期才能完成，例如1976年MOS Technology
公司生产的6502处理器，指令需要消耗2至7个时钟周期来完成\cite{6502manual}，
每个时钟周期只有一个执行部件（如读取指令、指令译码或算术运算）会在状态机的控制下被启用。对于
这类多周期处理器，其IPC远小于1。随着计算机体系结构研究的发展，尤其是1980年之后
RISC（Reduced Instruction Set Computer，精简指令集计算机）的出现，将执行一条
指令中不同操作的执行部件以流水线的形式安排，流水级间用寄存器隔开，就可以让处于不同
执行阶段（Stage）的、正在使用不同执行部件的指令“重叠”在一起。这种流水线式的微
架构，使得处理器的IPC不断逼近1，但仍无法超过1（在一个时钟周期内执行多条指令）。
使用上述两种IPC小于1的方案设计的处理器被统称为标量处理器（Scalar Processor）。

为了追求更高的性能，就要继续想方设法提高处理器的IPC，并使之大于1，也就是处理器
需要在一个时钟周期内执行多条指令。在只有一套执行部件的处理器中，在一个时钟周期
内执行多条指令是无法实现的。但通过在流水线方案的基础上设计多套执行部件，每一个
流水级中就可以容纳与执行部件数量相当的指令。对于有$N(N = 2,3,4,\cdots)$套执行部件的处理器，每个
时钟周期最多可以提交$N$条指令，这里的$N$也被称为发射宽度。也就是在最佳情况下，使用这种方案的处理器的IPC为
$N$。使用这种IPC可以大于1方案设计的处理器被称为超标量处理器（Super-scalar Processor）。
由于这种方案在性能上的显著优势，现代高性能处理器几乎全部采用超标量设计方案。

多周期、流水线与超标量处理器中指令的执行流程如图\ref{fig:exec-cmp}所示。

\begin{figure}[ht]
	\centering
	\includegraphics[scale=1, page=2]{figs/figs.pdf}
	\caption{多周期、流水线与超标量处理器指令执行示意}
	\label{fig:exec-cmp}
\end{figure}

对于$N$发射超标量处理器，要想使IPC尽可能接近$N$，需要在每个时钟周期向执行部件
提供合适的指令（Issue，发射），避免执行部件空转。然而在每个时钟周期都选择$N$条可以并行
执行的指令并不容易，这是因为指令间往往存在依赖关系，相互间存在依赖关系的指令无法
并行执行。指令间的依赖关系主要分为两种：
数据依赖和控制流依赖。数据依赖是指后续指令的源操作数是前序指令的目标操作数的情况，
常见于算术运算指令间或存储器访问指令与算术运算指令间。控制依赖是指分支指令后的指令
是否执行取决于分支条件判断结果的情况。

要避免数据依赖影响指令的发射，可以通过调整指令的顺序，从后续指令流中选取尽可能多
相互之间无依赖关系的指令进行发射，这种操作被称为指令的动态调度（Dynamic Scheduling）。
但调整指令执行顺序会打破指令集中规定的指令流顺序执行抽象，这就需要使用一些手段使得
指令的执行结果变得对程序员可见（指令对体系结构状态的修改，也就是提交）按照程序指令
流顺序发生，常见的此类手段为重排序缓冲区（Reorder Buffer）。这种在处理器运行过程
中动态调整程序指令顺序的技术被称为乱序执行（Out-of-Order Execution）。

而为了减小指令间的控制流依赖对指令的发射造成负面影响，可以在指令流遇到分支时预测
指令流跳转的方向以及跳转目标，这样不必等待分支条件计算，也就不会导致指令流的中断。
这种手段行之有效的原因是：分支指令的条件判断结果在统计学上存在一定的规律，并且不
同的分支指令判断结果的历史间也存在着一定的联系。目前成熟的分支预测器在绝大部分情
况下对分支跳转方向的预测正确率可达到95\%以上。此外，处理器在沿着猜测的分支方向
执行时，也会保留分支点状态的快照，这样即使分支条件的计算结果证明先前的猜测是错误的，
处理器也可以很快将状态恢复到分支点，并继续沿着正确的分支方向执行。这种在得到分支
条件计算结果前沿着预测的跳转方向继续执行的技术被称为预测式执行（Speculative Execution）。

运用上述乱序执行以及预测式执行的机制，现代高性能处理器的IPC已经可以达到3这样的
较高水平\cite{zhao2020sonicboom}，并且处理器执行流水线的性能已经不是整个处理
器系统的瓶颈。俗话说“巧妇难为无米之炊”，处理器执行流水线所需的指令和数据都存储
在动态随机存储器（Dynamic Random Access Memory，DRAM）中，但DRAM的访问延迟
多为数百纳秒，近千倍于处理器主频。这意味着如果不采取措施，处理器每次从DRAM中
读取指令和数据时，都要等待近千个时钟周期。为了解决DRAM延迟与处理器速度不匹配的
问题，现代处理器的存储器子系统采用分级的架构：越靠近处理器执行流水线的存储器
容量越小，但延迟越低，例如可以将与流水线工作在同一频率的体系结构寄存器视为一级
“缓存”，其容量最小，但延迟为零。并在DRAM到寄存器间插入多级（一般为2至3级）高速
缓存（Cache）。采取分级存储器子系统设计方案的原因主要有两个：
一是受到当前半导体器件工艺的限制，存储器的容量和延迟成反比，即越小越快，越大越慢；
二是程序访问存储器（包括指令和数据）的模式具有时间局部性和空间局部性的特点，也
就是程序近期访问的存储器地址也可能在将来再次被访问，并且这一地址附近的地址也可能
在将来被访问到。图\ref{fig:mem-heir}给出了一款处理器（Intel Core i7-10875H）
的存储器子系统示意图，图中注明了各级存储器的容量及延迟。

\begin{figure}[ht]
	\centering
	\includegraphics[scale=1, page=3]{figs/figs.pdf}
	\caption{存储器子系统分级示意}
	\label{fig:mem-heir}
\end{figure}

综上所述，现代高性能处理器主要采用的设计方案是：具有乱序执行以及预测式执行特点的
超标量流水线，和分级的存储器子系统。


\section{香山处理器南湖微架构简介}{Introduction to Nanhu Microarchitecture of Xiangshan Processor} \label{sec:xiangshan}
香山处理器是2019年在中国科学院支持下，由中国科学院计算技术研究所牵头发起的高性能开源
RISC-V处理器项目。南湖是香山处理器第二版微架构代号，支持RV64GCBK指令集，已在2022年3月
完成RTL代码冻结，正在进行后端设计验证流程并将在2022年上半年完成投片，目标是在14nm工艺
节点下频率达到2GHz。

南湖微架构的流水线分为前端和后端两个部分。前端流水线包括分支预测单元、取指单元、指令
缓冲等单元，预测式地取指。后端包括译码、重命名、重定序缓冲、保留站、整型/浮点寄存器堆、
整型/浮点运算单元、访存流水线（包括两条读取流水线，两条写入地址流水线，
两条写入数据流水线，以及独立的读取队列、写入队列和写入缓冲区等）。其微架构如图\ref{fig:nanhu-uarch}所示。

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{figs/nanhu.png}
	\caption{南湖微架构\cite{noauthor_openxiangshan/xiangshan:_nodate}}
	\label{fig:nanhu-uarch}
\end{figure}

由于本章展示的攻击方案围绕南湖微架构展开，本小节将对南湖微架构中与攻击方案有关的预测式
执行、乱序执行机制以及存储器子系统的设计作简单的介绍。

\clearpage

\subsection{预测式执行机制}{Speculative Execution Mechanism}
进入南湖微架构执行流水线的每一条指令的地址都是由分支预测单元（Branch Prediction Unit）提供的。
南湖微架构采取了一种分支预测和指令缓存解耦的取指架构，分支预测单元预测接下来的取指地址，
作为取指请求写入一个队列，这个队列将其发往取指单元，用于读取指令高速缓存（Instruction Cache）。

分支预测单元采用一种多级混合预测的架构，其主要组成部分包括：下一行预测器（Next Line Predictor，NLP）
和精确预测器（Accurate Predictor，APD）。其中，NLP是一个小型跳转目标缓冲区（Micro Branch Target Buffer），
用较小的存储开销提供一个无空泡的快速预测流。
APD中运用了TAGE-SC（TAgged GEometric Length Predictor with Statistical Corrector）
算法用来预测分支方向，并设计有取指地址缓冲区（Fetch Target Buffer）和返回地址栈（Return Address Stack）
用以提供跳转地址。
上述部件都将流水线的提交记录作为训练源，以实现根据历史指令流预测未来指令流的功能。

\subsection{乱序执行机制}{Out-of-Order Execution Mechanism}
在指令的发射阶段，南湖微架构使用保留站（Reservation Station）这一结构选择依赖关系已得到
满足的指令送入执行单元，以实现乱序执行。保留站内的主要存储了指令状态、指令和依赖数据。
保留站对指令进行的操作主要有：在发射阶段的入队、选择、读数据和出队等，在写回阶段的监听
以及对等待指令的唤醒等。保留站的主要模块还包括选择逻辑，用来为入队指令分配空闲表项、选择
就绪的指令进行发射。

运用上述硬件结构，可以实现以数据就绪作为指令可以执行的标准，从而指令被执行的顺序可以和
程序指令流中指令出现的顺序不同。

\subsection{存储器子系统}{Memory Subsystem}
香山处理器南湖微架构的存储器子系统可以分为核内和核外两个部分。

位于核内的存储器子系统包括执行单元中的读取、写入地址、写入数据流水线，
读取队列、写入队列和写入缓冲区，与流水线紧耦合的一级数据高速缓存（L1 Data Cache），
以及存储器管理单元（MMU，包括转译后备缓冲器TLB以及页表遍历器TLB）。

位于核外的存储器子系统主要是二级高速缓存（L2 Cache）。这一高速缓存同时具有一致性管理器（Coherence Manager）
的功能，为基于目录的非包含高速缓存（Directory-Based Non-Inclusive Cache），这意味着
在二级高速缓存内维护者一个列表，记录了目前存在于一级高速缓存中的地址（但并不同时存储这些
地址对应的数据），这允许二级高速缓存在外部接口收到一致性维护请求后，通过内部接口通知一级
高速缓存提供最新的数据并将对应缓存行（Cache Line）置为无效状态。


\section{攻击方案}{Attack Plan} \label{sec:spectre}
本次攻击在采用Spectre边界检查绕过（Spectre v1 Bounds Check Bypass）\cite{kocher_spectre_2019}方案
的基础上，设计并实现了基于地址冲突替换（Evict）的高速缓存控制算法，
在香山处理器南湖微架构上实现对任意地址的读取。

首先介绍本攻击方案的攻击面（Attack Surface），也就是被攻击的点位。考虑如算法清单\ref{algo:victim}
所示的函数，$a1$是一个长度为$a1\_length$的数组，其中存放着合法的用于索引$a2$数组的下标，
$x$是一个来自外部并且攻击者可控的参数，用来索引$a1$。这样的结构在真实程序中十分常见，一个可能的例子是：$a2$
是一个存储结构体的数组，而$a1$中收集了一些具有特殊性质的结构体位于$a2$中的下标，此时算法清单\ref{algo:victim}
所示的函数就可以被用来访问这些具有特殊性质的结构体。

\begin{algorithm}
	\caption{Victim Function}\label{algo:victim}
	\hspace*{\algorithmicindent} \textbf{Input} $x$ \\
	\hspace*{\algorithmicindent} \textbf{Output} $data$
	\begin{algorithmic}[1]
		\Function{Victim}{}
			\If {$0 \leq x$ \textbf{and} $x < \textit{a1\_length}$} \label{line:guard}
				\State $index \gets \textbf{MEM}[a1 + x]$ \label{line:access-a1}
				\State $offset \gets \text{calculate\_offset}(index)$ \label{line:calc-off}
				\State $data \gets$ \textbf{MEM}$[a2 + offset]$ \label{line:access-a2}
			\Else
				\State $data \gets \text{some invalid value}$
			\EndIf
		\EndFunction
	\end{algorithmic}
\end{algorithm}

可以看到，由于$x$是来自外部的参数，为了安全起见，函数在第\ref{line:guard}行对其进行了边界检查
（Bounds Check），防止在第\ref{line:access-a1}行访问$a1$时越界。紧接着在第\ref{line:calc-off}行，
函数通过从$a1$中的第$x$个位置上取得的索引值，计算要访问的内容在$a2$中的偏移量，对于之前提到的
结构体的实例，calculate\_offset函数可以是简单地将索引值与结构体的大小相乘。在第\ref{line:access-a2}行，
函数使用计算好的偏移量访问$a2$对应的存储器区域。

假设上述函数对不可靠外部参数$x$未做校验就用于索引$a1$，即删去第\ref{line:guard}行的条件判断语句，
攻击者就可以利用第\ref{line:access-a1}行对$a1$的访问实现对任意存储器地址的读取，具体为：假设关注的
地址为$secret$，则可以令$malicious\_x=secret-a1$，并控制传入Victim函数的参数，使$x=malicious\_x$。
这样一来，第\ref{line:access-a1}行就变成了：
\begin{equation}
	\begin{aligned}
		index &\gets \textbf{MEM}[a1 + malicious\_x] \\
		\mbox{即\quad} index &\gets \textbf{MEM}[a1 + (secret - a1)] \notag\\
		\mbox{即\quad} index &\gets \textbf{MEM}[secret]
	\end{aligned}
\end{equation}
\noindent 此时，$index$中存储的即为$secret$地址中的内容。

首先介绍如何实现对第\ref{line:guard}行边界检查的绕过。
边界检查在运行时是以分支指令的形式存在的，现代高性能处理器的预测式执行机制
在分支方向无法及时确定时，会通过考察这一分支指令之前的执行结果，来推测此次的分支方向。如果
连续多次使用合法的$x$作为参数调用Victim函数，“训练（Train）”分支预测器，使其认为这一分支会向合法的
方向跳转，并在使用$x=malicious\_x$作为参数时使得分支指令的条件无法及时确定，就可以使处理
器预测式地使用$malicious\_x$执行访问存储器的指令，从而读取$secret$地址中的内容作为$index$
并继续执行后续的指令。要使边界检查分支指令的条件无法快速确定有很多种手段，最简单的就是确保
在调用Victim函数前，$a1\_length$不存在于高速缓存中，这样会导致在分支条件判断时发生缓存缺失
（Cache Miss），由于上文提到的DRAM延迟较大的问题，就可以实现分支条件的延迟确定。

上述操作可以被称为“误导预测执行流”。
但值得注意的是，即使可以绕过边界检查，将位于$secret$地址的数据读取到$index$中，也要意识到
这些操作及后续执行的指令都是预测式地被执行的，随后一旦边界检查结果被最终确定为越界，上述指令
的执行结果并不会被提交进入体系结构状态，而是会被丢弃，所以这些指令也被称为瞬态指令（Transient
Instructions）。更加确定的是，$index$的值并不会直接返回给调用者，本文接下来讨论如何得到
$index$的值。

虽然瞬态指令的执行结果不会被提交进入体系结构状态，但它们仍然可能对非体结构的状态造成修改。
例如，对于瞬态存储器读取（Load）指令，虽然从存储器子系统读取到的数据不会写入体系结构寄存器
中，但会导致原本不在高速缓存中的被访问的缓存行被换入高速缓存中。读取指令的延时是不确定的，
在高速缓存命中时，请求的数据会很快从就近的高速缓存中返回，此时延时较低；同理当高速缓存缺失
时，请求的数据就需要从上一级高速缓存甚至DRAM中返回，此时延时较高。所以，只要在瞬态读取指令
执行前将瞬态指令可能访问的地址移出高速缓存（Flush），接着执行瞬态读取指令，执行的过程中，某个缓存行
会被重新移入高速缓存（Reload），随后经过探测对感兴趣的地址执行读取指令时所消耗的时间（Time），
就可以精确地确定瞬态读取指令访问的内存地址。这样的操作由\citet{gullasch2011cache}
在2011年首次提出，并被命名为Reload+Time缓存侧信道攻击。

至此，使用Spectre边界检查绕过攻击方案读取位于$secret$地址的数据的操作已经可以完整实现了，
其流程如算法清单\ref{algo:spectre}所示。

\begin{algorithm}
	\caption{Spectre Attack}\label{algo:spectre}
	\begin{algorithmic}[1]
		\Function{Spectre}{}
			\State flush $a2$ out of cache \label{line:flush-a2}
			\Repeat \label{line:train-begin}
				\State call Victim with legal $x$
			\Until{branch predictor is trained} \label{line:train-end}
			\State flush $a1\_length$ out of cache \label{line:flush-a1l}
			\State call Victim with $malicious\_x$ \label{line:call-victim}
			\For{$i \gets \text{possible values of }secret$} \label{line:time-begin}
				\State $result_{i} \gets \text{read\_latency}(\textbf{MEM}[a2 + \text{calculate\_offset}(i)])$
		  	\EndFor \label{line:time-end}
			\State $secret \gets \argmin\limits_{i} result_{i}$ \label{line:find-secret}
		\EndFunction
	\end{algorithmic}
\end{algorithm}

在Spectre攻击方案中，第\ref{line:flush-a2}行将$a2$整个移出高速缓存，为随后的Reload+Time缓存
侧信道攻击恢复$secret$做准备；第\ref{line:train-begin}至\ref{line:train-end}行使用合法的$x$调用
Victim函数，训练分支预测器使其认为$x$大概率处于边界之内；第\ref{line:flush-a1l}行将$a1_length$移出
高速缓存，以制造边界检查分支条件无法很快确定的情形；第\ref{line:call-victim}行使用将会导致处理器
预测式地执行对$secret$地址的读取指令的$malicious\_x$作为参数调用Victim函数，这会导致$a2$中某个与
$secret$地址中的数据值相关的缓存行被换入高速缓存内；第\ref{line:time-begin}至
\ref{line:time-end}行对每个$secret$地址中的数据的可能取值对应的$a2$中的地址进行读取测速，并将
读取所需的时间存储在$result$数组中；最后，第\ref{line:find-secret}行遍历$result$数组，其中访问时间最短
的$i$即最有可能为$secret$地址中的数据的值，至此Spectre攻击方案介绍完毕。

\section{可行性验证}{Feasibility Verification} \label{sec:spectre-impl}
为了证明上文中介绍的攻击方案的可行性，接下来将在香山高性能开源RISC-V处理器上实现缓存控制与检测算法与
误导预测执行流算法并最终实现完整的Spectre边界检查绕过攻击。

本文使用的香山处理器代码版本号（Commit ID）为5095522。

\subsection{缓存控制与检测}{Cache Manipulation and Measurement}
缓存控制与检测部分用于缓存侧信道攻击，其中控制主要是指将特定地址从高速缓存中换出（Flush），
检测是指测量对特定地址读取指令所耗费的时间。

控制特定地址从高速缓存中换出有多种方案，例如x86指令集处理器使用单独的clflush指令将指定地址
从整个存储器子系统的各级高速缓存中换出，写回DRAM；SiFive公司的HiFive Unmatched SoC使用一组映射
到存储器地址空间的控制寄存器（Memory Mapped I/O，MMIO）实现相同功能。

\begin{algorithm}
	\caption{Cache Evict}\label{algo:cache-evict}
	\hspace*{\algorithmicindent} \textbf{Input} $address$
	\begin{algorithmic}[1]
		\Function{Evict}{}
			\State $index \gets \text{get\_index}(address)$
			\For{$i \gets \text{ ways of the cache}$}
				\State access $\textbf{MEM}[\text{generate\_tag}(i) + index]$
		  	\EndFor
		\EndFunction
	\end{algorithmic}
\end{algorithm}

香山处理器没有提供从高速缓存中换出特点地址的
直接实现方案。由于从存储器地址空间中的地址到高速缓存行之间是多对一的映射关系，即有多个可能的地址被映射
到同一缓存行。基于这样的特点，可以通过访问与需要被换出的地址映射到相同缓存行的其他地址，将其他地址
换入高速缓存，替换（Evict）掉需要被换出的地址。这种算法涉及到的过程有：计算需要被换出地址对应的
高速缓存索引（Index）；生成一组与目标索引一致的候选地址；访问足够多的候选地址，以替换可能存在于
不同高速缓存路（Way）中的目标地址。具体流程如算法\ref{algo:cache-evict}所示。这一算法需要依据
高速缓存的参数实现候选地址的生成，表\ref{tab:cache-param}归纳了香山处理器精简配置的数据缓存参数。

\begin{table}[!ht]
	\centering
\begin{threeparttable}[b]
\zihao{5}
\caption{香山处理器MinimalConfig数据高速缓存参数}
\begin{tabular}{ccccc}
	\toprule
	高速缓存层级 & 缓存行大小（字节） & 缓存行索引数量 & 路数量 & 缓存总大小（字节） \\
	\midrule
	一级 & 64 & 64 & 8 & 32k \\
	二级 & 64 & 1024 & 8 & 512k \\
	\bottomrule
\end{tabular}
\label{tab:cache-param}
\end{threeparttable}
\end{table}

在缓存的检测部分，需要实现对特定地址执行读取指令所耗费的时间的精确测量。RISC-V指令集中，
设计有mcycle控制与状态寄存器（Control and Status Register，CSR），这一寄存器内存储有
处理器自最近一次复位以来已运行的时钟周期数，可作为准确的时间基准。在香山处理器设计中，对
CSR的读写指令会保证与其他指令间的严格顺序（即串行化），意味着乱序执行机制不会对存储器读取
指令时间的测量产生影响。所以只需在存储器读取指令前后各加入一条对mcycle寄存器的读取指令，
分别获得存储器读取前后的处理器时钟周期数，两者之差即为以时钟周期为单位的存储器读取延时。

为了测试上述缓存控制与检测方案的有效性，使用如算法\ref{algo:cache-test}所示的程序
进行测试。结果记录在表\ref{tab:cache-test-result}中。由测试结果可见：缓存控制与检测
方案有效，从一级高速缓存读取的延迟为16个时钟周期，从二级高速缓存读取的延迟为35个时钟周期，
从DRAM读取的延迟为约200至260个时钟周期.

\begin{breakablealgorithm}
	\caption{Timed Read}\label{algo:cache-test}
	\begin{algorithmic}[1]
		\Function{CacheManupulationTest}{}
			\Comment{system cold start, nothing in cache at the beginning}
			\State $address \gets \text{some address in DRAM address range}$
			\State $time1 \gets \text{timed\_read}(address)$
			\State $time2 \gets \text{timed\_read}(address)$
			\State $\text{evict\_l1}(address)$
			\State $time3 \gets \text{timed\_read}(address)$
			\State $\text{evict\_l1}(address)$
			\State $\text{evict\_l2}(address)$
			\State $time4 \gets \text{timed\_read}(address)$
			\State $time5 \gets \text{timed\_read}(address)$
		\EndFunction
	\end{algorithmic}
\end{breakablealgorithm}

\begin{table}[!ht]
	\centering
\begin{threeparttable}[b]
\zihao{5}
\caption{缓存控制与检测方案测试结果}
\begin{tabular}{x{0.2\textwidth}x{0.2\textwidth}}
	\toprule
	结果项 & 结果值 \\
	\midrule
	time1 & 194 \\
	time2 & 16 \\
	time3 & 35 \\
	time4 & 259 \\
	time5 & 16 \\
	\bottomrule
\end{tabular}
\label{tab:cache-test-result}
\end{threeparttable}
\end{table}

\subsection{误导预测执行流}{Misleading Speculative Execution Stream}
为了误导预测执行流，需要先对分支预测器进行训练，即连续多次使用合法参数调用Victim函数。
本攻击实例采用训练5次攻击1次的方案，最简单的实现方案如图\ref{fig:attach-with-branch}
中的C语言代码所示。

\begin{figure}[ht]
	\centering
	\begin{lstlisting}[language=c, escapechar=|]
for (int i = 0; i < 30; i++) {
	if (i % 6 == 0) { |\label{line:related-branch}|
		victim(malicious_x); |\label{line:bad-attack}|
	} else {
		victim(legal_x);
	}
}
	\end{lstlisting}
	\caption{包含条件判断的攻击代码}
	\label{fig:attach-with-branch}
\end{figure}

实验表明上述代码无法正常误导预测执行流，分支预测器会判定第\ref{line:bad-attack}行对Victim
函数的调用参数越界。这是因为分支预测器除了会考量当前分支指令的历史（Local History，局部历史），
也会根据最近执行过的其他分支指令的跳转方向（全局历史，Global History）做出预测。所以分支预测器
正确地推测出了第\ref{line:related-branch}行的分支与边界检查分支有关联。为了解决这个问题，需要
在不使用条件判断分支指令的情况下选择合法的$x$或攻击用的$malicious\_x$作为参数传递给Victim函数。

\begin{figure}[ht]
	\centering
	\begin{lstlisting}[language=c, escapechar=~]
for (int i = 0; i < 30; i++) {
	uint32_t upper_mask = ((i % 6) - 1) & 0xFFFF0000; ~\label{line:gen-upper}~
	uint32_t full_mask = (upper_mask | (upper_mask >> 16)); ~\label{line:gen-full}~
	uint32_t x = legal_x ^ (full_mask & (malicious_x ^ legal_x)); ~\label{line:select-x}~
	victim(x); ~\label{line:call-victim}~
}
	\end{lstlisting}
	\caption{不包含条件判断的攻击代码}
	\label{fig:attach-without-branch}
\end{figure}

图\ref{fig:attach-without-branch}所示的C语言代码实现了相同的功能，但没有额外的分支语句对攻击
指令流造成干扰，其原理如下：第\ref{line:gen-upper}行生成高16位掩码，第\ref{line:gen-full}行生成
完整的32位掩码，第\ref{line:select-x}行使用32位掩码选择legal\_x或malicious\_x作为x的值，
第\ref{line:call-victim}行调用Victim函数。第\ref{line:gen-upper}和\ref{line:gen-full}行
分步生成掩码是因为表达式(i \% 6) - 1在(i \% 6) $\in \{1,2,3,4,5\}$时高16位均为0，但低16位的
部分不能确定，在(i \% 6)为0时高16位均为1，这样可以稳定生成高16位部分的掩码，随后将高16位
复制到低16位区域，即可实现生成完整掩码。这样，在(i \% 6) != 0的训练轮，掩码full\_mask各位均为0，
(full\_mask \& (malicious\_x \^{} legal\_x))也为0，并且由于公式\ref{eq:xor-1}的性质，x取值legal\_x；
在(i \% 6) == 0的攻击轮，掩码full\_mask各位全为1，
(full\_mask \& (malicious\_x \^{} legal\_x))取值(malicious\_x \^{} legal\_x)，并且由于公式\ref{eq:xor-2}的性质，
x取值malicious\_x；
表\ref{tab:var-list}列出了两种不同情况下算法中各变量的取值情况。

\begin{equation}
    X \oplus 0 = X \label{eq:xor-1}
\end{equation}
\begin{equation}
	a \oplus X \oplus a = X \label{eq:xor-2}
\end{equation}

\begin{table}
	\centering
\begin{threeparttable}[b]
\zihao{5}
\caption{不包含条件判断的攻击代码变量取值情况}
\begin{tabular}{x{0.2\textwidth}x{0.2\textwidth}x{0.2\textwidth}}
	\toprule
	变量名 & \shortstack{(i \% 6) != 0 \\ 训练轮} & \shortstack{(i \% 6) == 0 \\ 攻击轮} \\
	\midrule
	upper\_mask & 0x0000\_0000 & 0xFFFF\_0000 \\
	full\_mask & 0x0000\_0000 & 0xFFFF\_FFFF \\
	x & legal\_x & malicious\_x \\
	\bottomrule
\end{tabular}
\label{tab:var-list}
\end{threeparttable}
\end{table}

\newpage

\subsection{香山南湖架构攻击验证}{Attack Verification on Nanhu Microarchitecture}
附录\ref{app:spectre-code}中列出了上一小节中介绍的Spectre边界检查绕过攻击方案的C语言实现，阅读代码可以发现
作为攻击目标的模拟秘密数据secret值被设置为了字母G（其ASCII值为71），在整个攻击程序中，
没有任何代码直接读取了secret的值。
编译后，在香山处理器南湖微架构的RTL仿真器上运行这一漏洞利用程序，得到了
如\ref{fig:spectre-result}图所示的结果。

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\textwidth]{figs/spectre-result.png}
	\caption{Spectre漏洞利用程序运行结果}
	\label{fig:spectre-result}
\end{figure}

可见程序给出了3个以字节值排序的可能的secret值，对于字节值在可打印ASCII区间的结果，
其对应字符显示在单引号中：其中字母G，是secret的值，证明本章
介绍的攻击方案有效，可在未授权情况下读取任意地址的值。
剩余的两个值是为噪声，均可通过统计学方法消除，具体分析如下：
3是用于训练分支预测器使用的参数，在更精密设计的
攻击程序中，可以通过多次执行攻击，轮换分支预测器训练值来降低这类干扰；253出现的原因是
由于高速缓存作为传递秘密信息的侧信道，其信噪比较低导致的，也可以通过多次执行攻击并通过
统计手段滤除此类干扰。


\section{本章小结}{Chapter Summary}
本章主要介绍了针对处理器微架构攻击：利用Spectre边界检查绕过方案，结合专为香山处理器
设计的高速缓存Evict控制算法，在南湖微架构上实现对任意地址的读取攻击目标。

\ref{sec:design-philo}介绍了现代高性能处理器的设计理念：超标量流水线、乱序执行、预测式执行和存储器子系统
分层高速缓存，以及这些理念产生的背景。

\ref{sec:xiangshan}介绍了现代高性能处理器的一个实例：香山处理器的南湖微架构，
在此基础上详细说明了南湖微架构中与本次展示的攻击方案有关的部分。

\ref{sec:spectre}介绍了Spectre边界检查绕过攻击方案的整体思路，
并着重阐述了利用预测式执行机制绕过边界检查、
使用高速缓存侧信道传递信息的原理与步骤。

\ref{sec:spectre-impl}使用C语言实现了攻击方案，并针对需要特别注意的实现细节进行了特别说明：
使用Evict算法实现高速缓存控制；使用无分支的指令流训练分支预测器。
在香山处理器RTL仿真器上验证了攻击方案的可行性：攻击者通过执行看似正常的指令流，
在未获得授权的情况下也可以实现对任意地址的读取。


\newpage
